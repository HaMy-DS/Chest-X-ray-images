{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#import lib"],"metadata":{"id":"iaDh-SHWteWg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXNrfAmEBe0W"},"outputs":[],"source":["from keras.applications.vgg16 import VGG16\n","import tensorflow as tf\n","import os\n","import sys"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"],"metadata":{"id":"PGVNXEerCjyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n"],"metadata":{"id":"I-xrezOzL1Ui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSr_JuY5JUp7"},"source":["#Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtMU75ngJ8VU"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvcOvA8KJYkP"},"outputs":[],"source":["path = '/content/drive/MyDrive/Đồ án KHDL - DS204.N21/Do_an/dataset_pneumonia/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LZPeTfyKI7z"},"outputs":[],"source":["PATH = path + 'data_augmentation'\n","IMG_SIZE = 224\n","IMG_CHANEL = 3\n","BATCH_SIZE = 256\n","COLOR_MODE = 'rgb'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJIgKqTSKkcI"},"outputs":[],"source":["CLASS_NAME = sorted(os.listdir(PATH + '/train'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcV0AZYOKve4"},"outputs":[],"source":["CLASS_NAME"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76obunMSKyeB"},"outputs":[],"source":["train_set = tf.keras.preprocessing.image_dataset_from_directory(\n","    PATH + '/train',\n","    labels = 'inferred',\n","    label_mode = 'binary',\n","    class_names = CLASS_NAME,\n","    color_mode = 'rgb',\n","    batch_size = 256,\n","    image_size = (IMG_SIZE,IMG_SIZE),\n","    validation_split=0.2,\n","    subset='training',\n","    seed=42,\n","    interpolation = 'bilinear',\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YdGF8U7N75U"},"outputs":[],"source":["val_set = tf.keras.preprocessing.image_dataset_from_directory(\n","    PATH + '/train',\n","    labels='inferred',\n","    label_mode='binary',\n","    class_names = CLASS_NAME,\n","    color_mode='rgb',\n","    batch_size=256,\n","    image_size=(IMG_SIZE, IMG_SIZE),\n","    validation_split=0.2, # Chia tỷ lệ 20% cho validation\n","    subset='validation',\n","    seed=42\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9t1yaWMK6qt"},"outputs":[],"source":["test_set = tf.keras.preprocessing.image_dataset_from_directory(\n","    PATH  + '/test',\n","    labels = 'inferred',\n","    label_mode = 'binary',\n","    class_names = sorted(os.listdir(PATH + '/train')),\n","    color_mode = 'rgb',\n","    batch_size = 256,\n","    image_size = (IMG_SIZE,IMG_SIZE),\n","    interpolation = 'bilinear',\n",")"]},{"cell_type":"markdown","source":["# grad-cam"],"metadata":{"id":"9-yNnWzuy_wc"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Display\n","from IPython.display import Image, display\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm"],"metadata":{"id":"BaMSoS81zBNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","#load model\n","model = keras.models.load_model('/content/drive/MyDrive/Đồ án KHDL - DS204.N21/Do_an/code_without_segmentation/resnet50_org.h5')"],"metadata":{"id":"zo2j-BMOzRZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction=model.predict(test_set)\n","y_pred_total = []\n","for i in range(0,len(prediction)):\n","    if prediction[i][0]>prediction[i][1]:  #Printing the prediction of model.\n","        y_pred_total.append(0)\n","    else:\n","        y_pred_total.append(1)\n"],"metadata":{"id":"cz2Ee-uSyZrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from glob import glob"],"metadata":{"id":"o2zFLC9bzsr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = glob('dataset_pneumonia/data_augmentation/train/*')"],"metadata":{"id":"B52YNNZuzpgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","for img, label in test_set:\n","  y_true  += np.array(label).flatten().tolist()"],"metadata":{"id":"kcKZps49ykqc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Đánh giá mô hình bằng các độ đo: Accuracy, Precision, Recall và F1-score\n","print(\"Mô hình DenseNet121 - Bộ dữ liệu\")\n","print(\"accuracy: \", accuracy_score(y_pred_total, y_true)*100)\n","print(\"f1_score: \", f1_score(y_pred_total, y_true, average= 'macro')*100)\n","print(\"precision: \", precision_score(y_pred_total, y_true)*100)\n","print(\"recall: \", recall_score(y_pred_total, y_true)*100)"],"metadata":{"id":"Q0yAuGf9z3O-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_true, y_pred_total, target_names=['NORMAL', 'PNEUMONIA']))"],"metadata":{"id":"zn_qe8RgLuR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_path = '/content/drive/MyDrive/Đồ án KHDL - DS204.N21/Do_an/Đồ án KHDL - DS204.N21/Do_an/dataset_pneumonia/data_augmentation/test/PNEUMONIA/person78_bacteria_380.jpeg'"],"metadata":{"id":"vmc9JqBLgG6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["size = (224,224)"],"metadata":{"id":"z_gZV_bUgQvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_img_array(img_path, size):\n","    # `img` is a PIL image of size 299x299\n","    img = keras.utils.load_img(img_path, target_size=size)\n","    # `array` is a float32 Numpy array of shape (299, 299, 3)\n","    array = keras.utils.img_to_array(img)\n","    # We add a dimension to transform our array into a \"batch\"\n","    # of size (1, 299, 299, 3)\n","    array = np.expand_dims(array, axis=0)\n","    return array\n","\n","\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()"],"metadata":{"id":"agj7uY78dGD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.inception_v3 import preprocess_input\n"],"metadata":{"id":"KFdZWNrohSR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_array = preprocess_input(get_img_array(img_path, size=size))\n","\n","# Remove last layer's softmax\n","model.layers[-1].activation = None\n","\n","# Print what the top predicted class is\n","preds = model.predict(img_array)\n","# print(\"Predicted:\", 1 if preds >= 0.5 else 0  )\n","if preds[0][0]>preds[0][1]:  #Printing the prediction of model.\n","  print(\"Predicted:\", 0)\n","else:\n","  print(\"Predicted:\", 1)\n","# Generate class activation heatmap\n","#layer cuối của mô hình cần được đổi tùy theo  mô hình\n","heatmap = make_gradcam_heatmap(img_array, model, 'concatenate_1')\n","\n","# Display heatmap\n","plt.matshow(heatmap)\n","plt.show()"],"metadata":{"id":"bPak4b3uf7L0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds[0][1]"],"metadata":{"id":"0Utksnb22ORi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n","    # Load the original image\n","    img = keras.utils.load_img(img_path)\n","    img = keras.utils.img_to_array(img)\n","\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = keras.utils.array_to_img(superimposed_img)\n","\n","    # Save the superimposed image\n","    superimposed_img.save(cam_path)\n","\n","    # Display Grad CAM\n","    display(Image(cam_path))\n","\n","#show 1 ảnh\n","save_and_display_gradcam(img_path, heatmap)"],"metadata":{"id":"kew_-88nhpVT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_save_1 = \"/content/drive/MyDrive/Đồ án KHDL - DS204.N21/Do_an/output/Grad-cam/inception_v3_aug/dự đoán đúng nhãn 1/\""],"metadata":{"id":"8gXPIcgMoOry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_save_0 = \"/content/drive/MyDrive/Đồ án KHDL - DS204.N21/Do_an/output/Grad-cam/inception_v3_aug/dự đoán sai nhãn 0 thành 1/\""],"metadata":{"id":"v3yAHwfioSli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_save_0 +str(0)+\".jpeg\""],"metadata":{"id":"FRGb2wV5ojmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#đường dẫn test-set\n","file_paths = test_set.file_paths\n"],"metadata":{"id":"Unk__6xuqHyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_paths"],"metadata":{"id":"f9IazTo1s6q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Lưu và show tập test\n","for idx,i in enumerate(y_true):\n","  if y_pred_total[idx] == i and i == 1:\n","    save_and_display_gradcam(file_paths[idx],heatmap,cam_path = path_save_1 +str(idx)+\".jpeg\")\n","  elif y_pred_total[idx] != i and y_pred_total[idx] ==1:\n","    save_and_display_gradcam(file_paths[idx],heatmap,cam_path = path_save_0 + str(idx)+\".jpeg\")\n","  i+=1"],"metadata":{"id":"Xrg0qZqfiZ_X"},"execution_count":null,"outputs":[]}]}